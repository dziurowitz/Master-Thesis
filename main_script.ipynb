{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bibs\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import pydot\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.layers import Input\n",
    "from tensorflow.python.keras.layers.core import Dropout, Lambda\n",
    "from tensorflow.python.keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from tensorflow.python.keras.layers.pooling import MaxPooling2D\n",
    "from tensorflow.python.keras.layers.merge import concatenate\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data paths\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "img_dir = os.path.join(data_dir, 'images_test') #hfusg images of atopic dermatitis\n",
    "mask_dir = os.path.join(data_dir, 'masks_test') #masks of SLEB layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data preparation\n",
    "X, y = [], []\n",
    "IMG_WIDTH, IMG_HEIGHT = 256, 256\n",
    "\n",
    "#looping through image files\n",
    "for file in tqdm(os.listdir(img_dir)):\n",
    "    \n",
    "    fullpath = os.path.join(img_dir, file)\n",
    "    img = cv2.imread(fullpath)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    #resize images to the size of network input\n",
    "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    X.append(img)\n",
    "\n",
    "\n",
    "#looping through mask files\n",
    "for file in tqdm(os.listdir(mask_dir)):\n",
    "    \n",
    "    fullpath = os.path.join(mask_dir, file)\n",
    "    #getting into .mat file from matlab, where masks are storaged\n",
    "    mat_file =  sio.loadmat(fullpath)\n",
    "    mat_e= mat_file['E']\n",
    "    mat_e= mat_e['e']\n",
    "    mat_arrs = mat_e[0].ravel()\n",
    "    arrs = mat_arrs[0]\n",
    "    arr = arrs[0,0]['azs']\n",
    "    #resize images to the size of network input\n",
    "    arr = cv2.resize(arr, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    y.append(arr)\n",
    "\n",
    "print(arr.shape)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correction of data - unifying images and masks dimensions\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check - image and mask\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(X[1], cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(y[1], cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "x_length = len(X)\n",
    "y = y.reshape((x_length,256,256,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "def data_aug(X_train,X_test,y_train,y_test,train_batch_size,test_batch_size):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0,\n",
    "        height_shift_range=0,\n",
    "        rescale=1.0/255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "    test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "    train_batch = train_datagen.flow(X_train,y_train,batch_size=train_batch_size)\n",
    "    test_batch = test_datagen.flow(X_test,y_test,batch_size=test_batch_size)\n",
    "    return (train_batch,test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric function Intersection over Union IoU (Jaccard Index)\n",
    "smooth = 1.\n",
    "def mean_iou(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#convolutional neural network model (u-net architecture)\n",
    "def create_unet(img_height, img_width, channels): \n",
    "    inputs = Input((img_height, img_width,  channels))\n",
    "\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)\n",
    "    c1 = Dropout(0.1) (c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "    c2 = Dropout(0.1) (c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "    c3 = Dropout(0.2) (c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "    c4 = Dropout(0.2) (c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "    c5 = Dropout(0.3) (c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "    c6 = Dropout(0.2) (c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "    c7 = Dropout(0.2) (c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "    c8 = Dropout(0.1) (c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "    c9 = Dropout(0.1) (c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "    #output is a mask, size of 256x256\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks setting\n",
    "def callbacks():\n",
    "    \n",
    "    callback = []\n",
    "    tb = TensorBoard(log_dir='logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "    callback.append(tb)\n",
    "    #adding different callbacks\n",
    "    \n",
    "    #checking learning progress\n",
    "    checkpoint = ModelCheckpoint(filepath=model_name,\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "    callback.append(checkpoint)\n",
    "    #early stoppage of epoch\n",
    "    earlystop = EarlyStopping(monitor = \"val_loss\", #val_loss \n",
    "                              min_delta = 0, \n",
    "                              patience = 8,\n",
    "                              mode=\"min\",\n",
    "                              verbose = 1,\n",
    "                              restore_best_weights = True)\n",
    "    callback.append(earlystop)\n",
    "\n",
    "    #reducing learning rate value \n",
    "    reducelr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                  factor=0.2,\n",
    "                                  patience=3, \n",
    "                                  min_lr=0.0001, \n",
    "                                  verbose=1)\n",
    "    callback.append(reducelr)\n",
    "    \n",
    "    return callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting cross-validation and learning model\n",
    "kfold = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "cvscores = []\n",
    "fold_number = 1\n",
    "train_X = X\n",
    "train_y = y\n",
    "for train_index, val_index in kfold.split(train_X):\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    print ('Fold: ',fold_number)\n",
    "    X_train, X_val = train_X[train_index], train_X[val_index]\n",
    "    y_train, y_val = train_y[train_index], train_y[val_index]\n",
    "    \n",
    "    #data augmentation\n",
    "    batch_size = 5\n",
    "    train_batch, val_batch = data_aug(X_train,X_val,y_train,y_val, batch_size, batch_size)\n",
    "    model_name = 'unet_fold_'+str(fold_number)+'.h5'\n",
    "    callback = callbacks()\n",
    "    \n",
    "    #create unet model\n",
    "    model = create_unet(IMG_HEIGHT,IMG_WIDTH,3)\n",
    "    \n",
    "  \n",
    "    epochs = 25 \n",
    "    model.fit_generator(train_batch, validation_data=val_batch, epochs=epochs, \n",
    "                        validation_steps= X_val.shape[0] // batch_size, \n",
    "                        steps_per_epoch= X_train.shape[0] // batch_size, \n",
    "                        callbacks=callback)\n",
    "    \n",
    "    #save model from the current fold\n",
    "    model.save(model_name)\n",
    "    \n",
    "    #evaluate the model\n",
    "    scores = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)   \n",
    "    \n",
    "    fold_number = fold_number + 1\n",
    "\n",
    "print(\"%s: %.2f%%\" % (\"Mean Accuracy: \",np.mean(cvscores)))\n",
    "print(\"%s: %.2f%%\" % (\"Standard Deviation: +/-\", np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensembling models created by cross-validation\n",
    "def ensemble(models, model_input):\n",
    "    \n",
    "    Models_output=[model(model_input) for model in models]\n",
    "    avg = keras.layers.average(Models_output)\n",
    "    \n",
    "    modelEnsemble = Model(inputs=model_input, outputs=avg, name='ensemble')\n",
    "    modelEnsemble.summary()\n",
    "    modelEnsemble.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['mean_iou'])\n",
    "    return modelEnsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fold_1 = create_unet(IMG_HEIGHT,IMG_WIDTH,3)\n",
    "model_fold_2 = create_unet(IMG_HEIGHT,IMG_WIDTH,3)\n",
    "model_fold_3 = create_unet(IMG_HEIGHT,IMG_WIDTH,3)\n",
    "model_fold_4 = create_unet(IMG_HEIGHT,IMG_WIDTH,3)\n",
    "\n",
    "models = []\n",
    "\n",
    "#load weights from each model\n",
    "model_fold_1.load_weights('unet_fold_1.h5')\n",
    "model_fold_1.name = 'model_1'\n",
    "models.append(model_1)\n",
    "\n",
    "model_fold_2.load_weights('unet_fold_2.h5')\n",
    "model_fold_2.name = 'model_2'\n",
    "models.append(model_2)\n",
    "\n",
    "model_fold_3.load_weights('unet_fold_3.h5')\n",
    "model_fold_3.name = 'model_3'\n",
    "models.append(model_3)\n",
    "\n",
    "model_fold_4.load_weights('unet_fold_4.h5')\n",
    "model_fold_4.name = 'model_4'\n",
    "models.append(model_4)\n",
    "\n",
    "model_input = Input(shape=models[0].input_shape[1:])\n",
    "ensemble_model = ensemble(models, model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate ensembled model\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scores = ensemble_model.evaluate(X_val, y_val, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (ensemble_model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "model_name = 'unet_ensembled.h5'\n",
    "ensemble_model.save(model_name)\n",
    "\n",
    "#plot network architecture\n",
    "plot_model(ensemble_model, show_shapes=True, show_layer_names=False)\n",
    "img = cv2.imread('model.png',1)\n",
    "plt.figure(figsize=(30,15))\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict data\n",
    "probability = ensemble_model.predict(X,batch_size=None,steps=1)\n",
    "print(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network prediction of SLEB layer\n",
    "x = x.reshape(1,256,256,3)\n",
    "pred = model.predict(x)\n",
    "pred = pred.reshape(256,256)\n",
    "print(np.unique(pred))\n",
    "\n",
    "for w in range(0,256):\n",
    "    for h  in range(0,256):\n",
    "        \n",
    "        if pred[w,h] > 0.9: #threshold of propability matrix, range [0,1].\n",
    "                            #1 is 100% sureness of network pixel belongs to SLEB layer\n",
    "            pred[w,h] = 1\n",
    "        else:\n",
    "            pred[w,h] = 0\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(pred, cmap='gray')\n",
    "plt.axis('off')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
